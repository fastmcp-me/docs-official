---
title: Context Relevance (Query Adherence)
description: Understand how to measure the relevance of context provided to user queries
---

import { Pill } from "/snippets/components/pill.mdx";
import { DefinitionCard } from "/snippets/components/definition-card.mdx";

<DefinitionCard>
  <strong>Context Relevance</strong> measures if the context has enough information to answer the user query.
</DefinitionCard>

## Context relevance

Context Relevance measures if the context has enough information to answer the user query.

High Context Relevance values indicate strong confidence that there is enough context to answer the question. Low Context Relevance values are a sign that you need to increase your Top K, modify your retrieval strategy, or use better embeddings.

<Note type="info">
  Context Relevance is differentiated from [Context Adherence](/concepts/metrics/response-quality/context-adherence): Context Relevance evaluates whether the retrieved context is relevant to a user's query whereas Context Adherence determines how well the response aligns to provided context.
</Note>

## Best practices

<CardGroup cols={2}>
  <Card title="Use for Results Assessment" icon="chart-line">
    Leverage Context Relevance when assessing the quality of your retrieval system's results and determining how accurately it adheres to queries.

</Card>
  <Card title="Combine with Other Metrics" icon="link">
    Use context relevance alongside context adherence, correctness, and completeness metrics for a comprehensive view of response quality.

</Card>
</CardGroup>
