---
title: Log Using the Log Decorator
description: Learn how to use the Galileo log decorator to log functions to traces
---

{/*<!-- markdownlint-disable MD044 -->*/}

import InstallDependencies from "/snippets/content/install-dependencies-openai.mdx"

import SnippetCreateAppPython from "/snippets/code/python/how-to-guides/basics/basic-logging-with-decorator/create-app.mdx";
import SnippetImportPython from "/snippets/code/python/how-to-guides/basics/basic-logging-with-decorator/import.mdx";
import SnippetWrapperPython from "/snippets/code/python/how-to-guides/basics/basic-logging-with-decorator/wrapper.mdx";

import SnippetCreateAppTypeScript from "/snippets/code/typescript/how-to-guides/basics/basic-logging-with-decorator/create-app.mdx";
import SnippetImportTypeScript from "/snippets/code/typescript/how-to-guides/basics/basic-logging-with-decorator/import.mdx";
import SnippetWrapperTypeScript from "/snippets/code/typescript/how-to-guides/basics/basic-logging-with-decorator/wrapper.mdx";

{/*<!-- markdownlint-enable MD044 -->*/}

## Overview

This guide shows you how to log spans to Galileo using the `@log` decorator in Python, or the `log` wrapper in TypeScript to log function calls using the async OpenAI SDK as LLM spans.

In this guide you will:

1. [Set up a project with Galileo](#install-dependencies)
1. [Create a basic app to call OpenAI](#create-the-basic-app-to-call-openai)
1. [Add logging with the log decorator](#add-simple-logging-with-the-galileo-log-decorator-or-wrapper)

## Before you start

To complete this how-to, you will need:

- An [OpenAI API key](https://openai.com/api/)
- A [Galileo project](/concepts/projects) configured
- Your [Galileo API key](https://app.galileo.ai/settings/api-keys)

<InstallDependencies/>

## Create the basic app to call OpenAI

<Steps>
<Step title="Create a file for your application called app.py or app.ts."/>

<Step title="Add the following code to call OpenAI to ask a question">

<CodeGroup>
  <SnippetCreateAppPython />
  <SnippetCreateAppTypeScript />
</CodeGroup>

If you are using TypeScript, you will also need to configure your code to use ESM. Add the following to your `package.json` file:

```json package.json
{
  "type": "module",
  ... // Existing contents
}
```

</Step>

<Step title="Run the app to ensure everything is working">

<CodeGroup>

```bash Python
python app.py
```

```bash TypeScript
npx tsx app.ts
```

</CodeGroup>

You should see a description of Newton's first law.

```output
(.venv) âžœ  python app.py
Newton's First Law, also known as the Law of Inertia, states that an object
at rest will stay at rest and an object in motion will stay in motion with
the same speed and in the same direction, unless acted upon by an
unbalanced force. In simpler terms, it means that an object will keep doing
what it's currently doing until a force makes it do something different.
This law is fundamental to understanding motion and forces as it pertains
to physics.
```

</Step>
</Steps>

## Add simple logging with the Galileo log decorator or wrapper

Galileo has a `@log` decorator in Python, and a `log` wrapper in TypeScript that logs function calls as spans. If these decorated or wrapped calls are called whilst there is an active trace, they are added to that trace. If there is no active trace, a new one is created for this span.

In this guide, you will be adding the decorator or wrapper to log the function that calls OpenAI.

<Steps>

<Step title="Import the log decorator">

At the top of your file, add an import for the log decorator:

<CodeGroup>
  <SnippetImportPython />
  <SnippetImportTypeScript />
</CodeGroup>

</Step>

<Step title="Decorate or wrap the function">

Update the function definition to include the decorator or wrapper:

<CodeGroup>
  <SnippetWrapperPython />
  <SnippetWrapperTypeScript />
</CodeGroup>

This will log the function as an LLM span using the span type parameter. You can read more about these in our [span types documentation](/sdk-api/logging/log-decorator#span-types).

This also sets the name of the span to "OpenAI GPT-4o-mini".

</Step>

<Step title="Run the app">

<CodeGroup>

```bash Python
python app.py
```

```bash TypeScript
npx tsx app.ts
```

</CodeGroup>

When the app runs, the span will be logged automatically, with the input as the `prompt`, the output as the returned `response`. The duration will also be logged.

</Step>

<Step title="View the logged trace">

From the [Galileo Console](https://app.galileo.ai), open the Log stream for your project. You will see a trace with a single span containing the logged function call.

Select the trace to see a detailed view:

![A trace with an input, OpenAI span, and an output](/how-to-guides/basics/basic-logging-with-decorator/trace.webp)

Select the OpenAI span to see the latency.

![The trace with the OpenAI span selected and the latency highlighted in the system metrics pane](/how-to-guides/basics/basic-logging-with-decorator/trace-latency.webp)

</Step>

</Steps>

Your logging is now set up! You are ready to configure metrics for your project.

## See also

- [Configure metrics](/concepts/metrics/overview)
- [Log streams](/concepts/logging/logstreams)
- [The `@log` decorator](/sdk-api/logging/log-decorator)
