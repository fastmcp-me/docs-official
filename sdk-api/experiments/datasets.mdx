---
title: Datasets
description: Learn how to create and manage datasets for use in your experiments with our SDKs
---

{/*<!-- markdownlint-disable MD044 -->*/}

import SnippetSdkDatasetsCreatePython from "/snippets/code/python/sdk/datasets/create.mdx";
import SnippetSdkDatasetsGetPython from "/snippets/code/python/sdk/datasets/get.mdx";
import SnippetSdkDatasetsAddRowsPython from "/snippets/code/python/sdk/datasets/add-rows.mdx";
import SnippetSdkDatasetsExtendPython from "/snippets/code/python/sdk/datasets/extend.mdx";
import SnippetSdkDatasetsListPython from "/snippets/code/python/sdk/datasets/list.mdx";
import SnippetSdkDatasetsDeletePython from "/snippets/code/python/sdk/datasets/delete.mdx";
import SnippetSdkDatasetsVersionsPython from "/snippets/code/python/sdk/datasets/versions.mdx";
import SnippetSdkDatasetsExperimentsPython from "/snippets/code/python/sdk/datasets/experiments.mdx";

import SnippetSdkDatasetsCreateTypeScript from "/snippets/code/typescript/sdk/datasets/create-dataset.mdx";
import SnippetSdkDatasetsGetTypeScript from "/snippets/code/typescript/sdk/datasets/get.mdx";
import SnippetSdkDatasetsAddRowsTypeScript from "/snippets/code/typescript/sdk/datasets/add-rows.mdx";
import SnippetSdkDatasetsExtendTypeScript from "/snippets/code/typescript/sdk/datasets/extend.mdx";
import SnippetSdkDatasetsListTypeScript from "/snippets/code/typescript/sdk/datasets/list.mdx";
import SnippetSdkDatasetsDeleteTypeScript from "/snippets/code/typescript/sdk/datasets/delete.mdx";
import SnippetSdkDatasetsVersionsTypeScript from "/snippets/code/typescript/sdk/datasets/versions.mdx";
import SnippetSdkDatasetsExperimentsTypeScript from "/snippets/code/typescript/sdk/datasets/experiments.mdx";

{/*<!-- markdownlint-enable MD044 -->*/}

Datasets allow you to store and reuse well-defined data for use in experiments. Datasets can be stored and versioned in Galileo, and available for experiments running both in the console as well as in code.

Dataset fields can be sent to a function that is being tested by your application, or used as input variables to [prompts](/sdk-api/experiments/prompts).

## Work with datasets

Datasets can be used in two ways:

1. [**Using the Galileo Console**](#create-and-manage-datasets-in-the-galileo-console)

   - Create and manage datasets directly through the Galileo Console
   - Visually organize and track test cases
   - No coding required

2. [**Using the Galileo SDK**](#create-and-manage-datasets-in-code)

   - Programmatically create and manage datasets using Python
   - Integrate dataset management into your existing workflows
   - Automate dataset operations

Choose the approach that best fits your workflow and team's needs. Many users combine both approaches, using code for bulk operations and the console for visualization and quick edits.

## Dataset fields

Each record in a Galileo dataset can have three top-level fields:

1. **`input`** - Input variables that can be passed to your application or prompt to recreate a test case.
1. **`output`** - Reference outputs to evaluate your application. These can be the ground truth for [BLEU, ROUGE](/concepts/metrics/expression-and-readability/bleu-and-rouge), and [Ground Truth Adherence](/concepts/metrics/response-quality/ground-truth-adherence) metrics, or reference outputs for manual reference.
1. **`metadata`** - Additional data you can use to filter or group your dataset.

## Create and manage datasets in the Galileo console

### Create a new dataset

The dataset creation button, is your starting point for organizing test cases in Galileo's interface.

From the **Datasets** page of your project, click the **+ Create Dataset** button.

![Dataset create dataset button](/images/dataset-create.png)

You can also create a dataset from a **Playground** page. Click the **Add Dataset** button, then select **+ Create new dataset**.

![Dataset creation from Playground](/images/dataset-playground-create.png)

You can choose to create a dataset by:

- [Uploading a dataset file](#dataset-file-uploads)
- [Auto-generating a synthetic dataset](#synthetic-data-generation)
- [Creating a dataset manually](#manual-dataset-creation)

![Dataset dialog options](/images/dataset-dialog-options.png)

#### Dataset file uploads

An uploaded file can be in CSV, JSON/JSONC, or Feather format. The file needs to have at least one column that maps to the input values. These columns can have any name.

Once you have uploaded the file, you can name the dataset, and map the columns in the file to the dataset's input, reference output, and metadata by dragging them from the *Original uploaded dataset* column to the relevant dataset column. Select the **Save dataset** button when you are done.

![Mapping a column called input to the input column](/images/dataset-match-columns.png)

#### Synthetic data generation

You can utilize Large Language Models (LLMs) to generate datasets that you can use to test your AI applications. These test datasets can be used before and after your app is deployed to production.

This feature requires an integration with a supported LLM provider (for example, OpenAI, Azure, Mistral). To configure an integration, visit the LLM provider's platform to obtain an API key, then add the key from the model selection dialog, or from Galileo's [integrations page](https://app.galileo.ai/settings/integrations).

![Synthetic data generation - LLM integrations](/images/dataset-synthetic-llm-integrations.png)

To generate data, provide **Input Examples** for the AI model. At least one example is required, though more examples can help improve the synthetic data.

![Synthetic data generation - Generated Data](/images/dataset-synthetic-default.jpg)

After data generation is completed, select **Save Dataset** to continue working with the data (including editing, exporting, and sharing the data).

You can also customize the generated data by setting:

- The number of rows that you ask the LLM to generate.
- The LLM model that you're utilizing.
- **Your AI app's use case** (Optional): What task is your AI app doing? For example, chatbot to answer customer service questions.
- **Special instructions** (Optional): Additional guidance to further refine the generated output.
- **The generated data types** (Optional): Customize data types that the generated data should follow.
  > Data types can be used for testing specific scenarios. For example, testing your app's resilience to prompt injection scenarios where attackers try to get your app to produce harmful output.

![Synthetic data generation - Customized Data](/images/dataset-synthetic-customized.jpg)

Synthetically generated data can be used in many scenarios -- expanding upon your existing datasets to increase test coverage and help you more quickly improve your AI applications.

#### Manual dataset creation

The console allows you to manually add and edit data rows. Select the **Save dataset** button when you are done.

![Dataset manual creation](/images/dataset-manual-create.png)

### Add rows to your dataset

You can manually add new rows to your dataset through the console, allowing you to capture problematic inputs or edge cases as you discover them.

![Adding a new row to an existing dataset](/images/dataset-manual-add-row.png)

After making changes to your dataset, select the **Save changes** button to create a new version that preserves your modifications while maintaining the history of previous versions.

### View version history

The version history view allows you to track changes to your dataset over time, see when modifications were made, and access previous versions for comparison or regression testing.

![Dataset versions](/images/dataset-versions.png)

After we add a new row to the dataset, we can see the version history by clicking the **Version History** tab.

![Creating a new version of your dataset](/images/dataset-versions-new-version.png)

## Create and manage datasets in code

### Create datasets

When you create a dataset, it is uploaded to Galileo and available to future experiments. Datasets need to have unique names, and are available to all projects across your organization.

<CodeGroup>
  <SnippetSdkDatasetsCreatePython />
  <SnippetSdkDatasetsCreateTypeScript />
</CodeGroup>

See the [`create_dataset` Python SDK docs](/sdk-api/python/reference/datasets#create-dataset) or [`createDataset` TypeScript SDK docs](/sdk-api/typescript/reference/README/functions/createDataset) for more details.

### Get existing datasets

Once a dataset has been created in Galileo, you can retrieve it to use in your experiments by name or ID.

<CodeGroup>
  <SnippetSdkDatasetsGetPython />
  <SnippetSdkDatasetsGetTypeScript />
</CodeGroup>

See the [`get_dataset` Python SDK docs](/sdk-api/python/reference/datasets#get-dataset) or [`getDataset` TypeScript SDK docs](/sdk-api/typescript/reference/README/functions/getDataset) for more details.

### Add rows to existing datasets

Once a dataset has been created, you can manually add rows to it.

<CodeGroup>
  <SnippetSdkDatasetsAddRowsPython />
  <SnippetSdkDatasetsAddRowsTypeScript />
</CodeGroup>

See the [`add_rows` Python SDK docs](/sdk-api/python/reference/datasets#add-rows) or [`addRowsToDataset` TypeScript SDK docs](/sdk-api/typescript/reference/README/functions/addRowsToDataset) for more details.

### Generate synthetic data to extend a dataset

Galileo can use an LLM integration to generate rows of synthetic data that you can then add to a dataset. This synthetic data is generated using a mixture of prompts, instructions, few-shot examples, and data types.

Once these rows have been generated, they can be added to a new or existing dataset.

<CodeGroup>
  <SnippetSdkDatasetsExtendPython />
  <SnippetSdkDatasetsExtendTypeScript />
</CodeGroup>

See the [`extend_dataset` Python SDK docs](/sdk-api/python/reference/datasets#extend-dataset) or [`extendDataset` TypeScript SDK docs](/sdk-api/typescript/reference/README/functions/extendDataset) for more details.

### List datasets

You can retrieve all the datasets for a project.

<CodeGroup>
  <SnippetSdkDatasetsListPython />
  <SnippetSdkDatasetsListTypeScript />
</CodeGroup>

See the [`list_datasets` Python SDK docs](/sdk-api/python/reference/datasets#list-datasets) or [`getDatasets` TypeScript SDK docs](/sdk-api/typescript/reference/README/functions/getDatasets) for more details.

### Delete datasets

If a dataset is no longer needed, you can delete it by name or ID.

<CodeGroup>
  <SnippetSdkDatasetsDeletePython />
  <SnippetSdkDatasetsDeleteTypeScript />
</CodeGroup>

See the [`delete_dataset` Python SDK docs](/sdk-api/python/reference/datasets#delete-dataset) or [`deleteDataset` TypeScript SDK docs](/sdk-api/typescript/reference/README/functions/deleteDataset) for more details.

### Work with dataset versions

Galileo automatically creates new versions of datasets when they are modified. You can access different versions by getting the dataset history.

<CodeGroup>
  <SnippetSdkDatasetsVersionsPython />
  <SnippetSdkDatasetsVersionsTypeScript />
</CodeGroup>

See the [`get_dataset_version_history` Python SDK docs](/sdk-api/python/reference/datasets#aget-dataset-version-history) for more details.

### Use datasets in experiments

Datasets are primarily used for running experiments to evaluate the performance of your LLM applications:

<CodeGroup>
  <SnippetSdkDatasetsExperimentsPython />
  <SnippetSdkDatasetsExperimentsTypeScript />
</CodeGroup>

## Best practices for dataset management

When working with datasets consider these tips:

1. Start small and representative: begin with a handful of diverse examples to validate quickly.
1. Grow incrementally: add cases as you find bugs, edge cases, or new scenarios.
1. Version thoughtfully: create new versions for significant changes and compare results over time.
1. Document changes: record the rationale behind additions and versions in comments or changelogs.
1. Organize by purpose: separate datasets for basics, edge cases, and regressions.
1. Choose the right approach: use the console for quick edits/visualization and the SDK for automation/bulk.
1. Track progress: monitor metrics/dashboards or review results to catch regressions.
1. Keep history: archive old cases and maintain version history—don’t delete.
1. Keep your dataset schema consistent: ensure every row includes all fields referenced by prompts.
1. Use nested access for dictionaries: reference nested fields with dot notation (e.g., `input.metadata.days`).
1. Test your prompt templates: render with sample rows to verify variable substitution.
1. Document your prompt templates: note required fields and assumptions near the template.

## Related resources

<CardGroup cols={2}>
<Card title="Datasets" icon="database" horizontal href="/sdk-api/experiments/datasets">
    Learn about more datasets, the data driving your experiments.
</Card>
<Card title="Experiments" icon="flask" horizontal href="/sdk-api/experiments/experiments">
    Learn how to use datasets and experiments to improve your application.
</Card>
<Card title="Prompt Templates" icon="message" horizontal href="/sdk-api/experiments/prompts">
    Learn how to create and use prompt templates in experiments
</Card>
</CardGroup>
