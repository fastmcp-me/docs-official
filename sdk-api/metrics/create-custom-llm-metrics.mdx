---
title: Custom LLM-as-a-Judge Metrics
description: Learn how to create custom LLM-as-a-judge metrics in code
---

{/*<!-- markdownlint-disable MD044 -->*/}

import SnippetPythonCreateMetric from "/snippets/code/python/sdk/metrics/create-metric.mdx"
// import SnippetPythonDeleteMetric from "/snippets/code/python/sdk/metrics/delete-metric.mdx"

import SnippetTypeScriptCreateMetric from "/snippets/code/typescript/sdk/metrics/create-metric.mdx"
import SnippetTypeScriptDeleteMetric from "/snippets/code/typescript/sdk/metrics/delete-metric.mdx"

{/*<!-- markdownlint-enable MD044 -->*/}

In addition to creating custom LLM-as-a-judge metrics through the [Galileo console](/concepts/metrics/custom-metrics/custom-metrics-ui-llm), you can also create these in code.

## Create a custom metric

When you create a custom metric, you need to provide a name and the prompt to use. You can optionally also provide the output type, what it applies to, span, trace, or session, the model to use, if reasoning should be generated, the number of LLM judges to use, and any tags.

<CodeGroup>

<SnippetPythonCreateMetric />
<SnippetTypeScriptCreateMetric />

</CodeGroup>

## Delete a custom metric

You can also delete a metric by name.

<CodeGroup>

{/*<SnippetPythonDeleteMetric />*/}
<SnippetTypeScriptDeleteMetric />

</CodeGroup>

## Next steps

<CardGroup cols={2}>
<Card title="Custom LLM-as-a-judge metrics" icon="brain" horizontal href="/concepts/metrics/custom-metrics/custom-metrics-ui-llm">
    Learn how to create evaluation metrics using LLMs to judge the quality of responses inside the Galileo console.
</Card>
<Card title="LLM-as-a-judge prompt engineering guide" icon="wrench" horizontal href="/concepts/metrics/custom-metrics/prompt-engineering">
    Learn best practices for prompt engineering with custom LLM-as-a-judge metrics.
</Card>
<Card title="Custom code-based metrics" icon="code" horizontal href="/concepts/metrics/custom-metrics/custom-metrics-ui-code">
    Learn how to create, register, and use custom code-based metrics to evaluate your LLM applications.
</Card>
</CardGroup>
