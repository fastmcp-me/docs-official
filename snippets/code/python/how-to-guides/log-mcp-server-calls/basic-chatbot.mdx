```python app.py
import asyncio
import os

from datetime import datetime

from anthropic import Anthropic, omit
from anthropic.types import Message

from dotenv import load_dotenv

from galileo import galileo_context

load_dotenv()  # load environment variables from .env

anthropic = Anthropic()
message_history = []

def call_llm(messages) -> Message:
    """
    Call the LLM with the provided query and return
    the response text
    """
    galileo_logger = galileo_context.get_logger_instance()

    # Capture the current time in nanoseconds for logging
    start_time_ns = datetime.now().timestamp() * 1_000_000_000

    # Call the LLM
    response = anthropic.messages.create(
        model=os.environ["ANTHROPIC_MODEL"],
        max_tokens=1000,
        messages=messages
    )

    # Log the LLM call
    for content in [c for c in response.content if c.type == "text"]:
        galileo_logger.add_llm_span(
            input=messages,
            output=content.text,
            model=os.environ["ANTHROPIC_MODEL"],
            num_input_tokens=response.usage.input_tokens,
            num_output_tokens=response.usage.output_tokens,
            total_tokens=response.usage.input_tokens + 
                         response.usage.output_tokens,
            duration_ns=int(
                (datetime.now().timestamp() * 1_000_000_000) - 
                start_time_ns
            ),
        )

    return response

async def process_query(query: str) -> str:
    """Process a query using Claude"""
    # Capture the current time in nanoseconds for logging
    start_time_ns = datetime.now().timestamp() * 1_000_000_000

    # Start a Galileo Logger trace
    galileo_logger = galileo_context.get_logger_instance()
    galileo_logger.start_trace(
        input=query,
        name="MCP Chatbot Query",
    )

    message_history.append({"role": "user", "content": query})

    # Call the LLM
    response = call_llm(message_history)

    # Process the response
    final_text = []
    
    for content in response.content:
        if content.type == "text":
            # Save the text response to the message history
            message_history.append({
                "role": "assistant",
                "content": content.text
            })
            final_text.append(content.text)

    # Conclude and flush the trace
    galileo_logger.conclude(
        output="\n".join(final_text),
        duration_ns=int(
            (datetime.now().timestamp() * 1_000_000_000) - 
            start_time_ns
        ),
    )
    galileo_logger.flush()

    # Return the final response text
    return "\n".join(final_text)

async def main():
    """Main function to run the chat loop"""
    # Start a Galileo Logger session
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    galileo_context.start_session(
        f"MCP Chatbot Session - {current_time}"
    )

    while True:
        query = input("\nQuery: ").strip()
        if query.lower() == "quit":
            break

        print(await process_query(query))

if __name__ == "__main__":
    asyncio.run(main())
```
