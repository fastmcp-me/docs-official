| Name | Description | Supported Nodes | When to Use | Example Use Case |
|:-----|:------------|:---------------|:------------|:-----------------|
| [Chunk Attribution Utilization](/concepts/metrics/response-quality/chunk-attribution) | Assesses whether the response uses the retrieved chunks in its response, and properly attributes information to source documents. | Retriever span | When implementing RAG systems and want to ensure proper attribution and that retrieved information is used efficiently. | A legal research assistant that must cite specific cases and statutes when providing legal information. |
| [Completeness](/concepts/metrics/response-quality/completeness) | Measures how thoroughly the response covers the relevant information available in the provided context | LLM span | When evaluating if responses fully address the user's intent. | A healthcare chatbot, when provided with a patient's medical record as context, must include all relevant critical information from that record in its response. |
| [Context Adherence](/concepts/metrics/response-quality/context-adherence) | Measures how well the response aligns with the provided context. | LLM span | When you want to ensure the model is grounding its responses in the provided context. | A financial advisor bot that must base investment recommendations on the client's specific financial situation and goals. |
| [Context Relevance (Query Adherence)](/concepts/metrics/response-quality/context-relevance) | Evaluates whether the retrieved context is relevant to the user's query. | Retriever span | When assessing the quality of your retrieval system's results. | An internal knowledge base search that retrieves company policies relevant to specific employee questions. |
| [Correctness (factuality)](/concepts/metrics/response-quality/correctness) | Evaluates the factual accuracy of information provided in the response. | LLM span | When accuracy of information is critical to your application. | A medical information system providing drug interaction details to healthcare professionals. |
| [Ground Truth Adherence](/concepts/metrics/response-quality/ground-truth-adherence) | Measures how well the response aligns with established ground truth.<br/><br/>This metric is only available for experiments as it needs ground truth set in your dataset. | Trace | When evaluating model responses against known correct answers. | A customer service AI that must provide accurate product specifications from an official catalog. |
| [Instruction Adherence](/concepts/metrics/response-quality/instruction-adherence) | Assesses whether the model followed the instructions in your prompt template. | LLM span | When using complex prompts and need to verify the model is following all instructions. | A content generation system that must follow specific brand guidelines and formatting requirements. |
